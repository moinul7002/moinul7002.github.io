{"componentChunkName":"component---src-pages-index-js","path":"/","result":{"data":{"allStrapiProjects":{"nodes":[{"github":"https://github.com/moinul7002/Multi-modal-Emotion-Recognition-with-Facial-and-Audio-Features","strapiId":31,"desc":"This project focuses on constructing a multi-modal emotion recognition system with facial and audio features. It employs subspace-based feature fusion methods, including z-score normalization and Canonical Correlation Analysis (CCA), to combine facial expression and audio features. SVM classifiers are trained using spatiotemporal features from 50 videos of 5 participants and evaluated using the remaining data. LOSO cross-validation is implemented for reliable performance estimation.","title":"Multi-Modal Emotion Recognition","url":null,"category":"Machine Learning","image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAQFAgP/xAAVAQEBAAAAAAAAAAAAAAAAAAACAf/aAAwDAQACEAMQAAABqLdlUaxkN//EABsQAAICAwEAAAAAAAAAAAAAAAEDAhIEMTIz/9oACAEBAAEFAsmdFrZGo070AFl8f//EABgRAAIDAAAAAAAAAAAAAAAAAAABAhEx/9oACAEDAQE/AZZYj//EABYRAQEBAAAAAAAAAAAAAAAAAAEQQf/aAAgBAgEBPwEMn//EABsQAAICAwEAAAAAAAAAAAAAAAABAiEQETFB/9oACAEBAAY/Ar46NLx4iSoR/8QAHRABAAICAgMAAAAAAAAAAAAAAQARIVEQMXGRsf/aAAgBAQABPyEFbaEsLKQPEOzMzcmvcJSOz5wv/9oADAMBAAIAAwAAABCI7//EABcRAAMBAAAAAAAAAAAAAAAAAAABIXH/2gAIAQMBAT8QjcpI/8QAFhEBAQEAAAAAAAAAAAAAAAAAAQAh/9oACAECAQE/ECdTjf/EABoQAQEBAQEBAQAAAAAAAAAAAAERIQAxYcH/2gAIAQEAAT8Q0BBpGvPbG441icco133iH/RrSzXGYC0D55LVufvf/9k=","aspectRatio":2,"src":"/static/156d686d3a5888960b90ae847d6392bd/14b42/9e1de0a2f898fd0a26a6a3afaa5a1260.jpg","srcSet":"/static/156d686d3a5888960b90ae847d6392bd/f836f/9e1de0a2f898fd0a26a6a3afaa5a1260.jpg 200w,\n/static/156d686d3a5888960b90ae847d6392bd/2244e/9e1de0a2f898fd0a26a6a3afaa5a1260.jpg 400w,\n/static/156d686d3a5888960b90ae847d6392bd/14b42/9e1de0a2f898fd0a26a6a3afaa5a1260.jpg 800w,\n/static/156d686d3a5888960b90ae847d6392bd/16310/9e1de0a2f898fd0a26a6a3afaa5a1260.jpg 1024w","sizes":"(max-width: 800px) 100vw, 800px"}}},"stack":[{"id":137,"title":"Scipy"},{"id":132,"title":"PCA"},{"id":135,"title":"SVM"},{"id":136,"title":"CCA"},{"id":133,"title":"NumPy"},{"id":134,"title":"LOSO"}]},{"github":"https://github.com/moinul7002/Deep-Learning-Project-2023","strapiId":19,"desc":"We worked with the miniImageNet focusing on the train.tar file and later split the data as train, val and test datasets. We pre-trained three models - ResNet18, VGG16 and Vision Transformer (ViT) with the best optimizers on the Training Set of MiniImageNet and then evaluated on the Validation Set and tested on the Testing Set. We saved the checkpoints for each of the models used to later use them on EuroSAT-RGB dataset. We took 5 classes from EuroSat-RGB dataset then randomply took samples as instructed in the project instruction. We used this dataset for transfer learning on the model checkpoints we saved for VGG16, ResNet18 and Vision Transformer (ViT).","title":"Transfer Learning with MiniImageNet and ViT","url":null,"category":"Deep Learning","image":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACTElEQVQoz21TS08TURjtn3NDCqilJAaFBgIkRNRqYmJilL54B1vU0HamM1OlPEp5NSZabYGpWhoTFy6MbhQ3LiTSGapuv+N37w0FExcn57uLe+Z895zxGBdNnEXmgiHx71nMBvTzJtLtFrQOE8k2Cx+Ss/hVG0NjN0zOXhgM8rQu+8xT9p35iE+JCZHCYAoH+QkcrE3g6+oE3GoIf+r34bCga4fh2iHyiEt6RwZau95izasr7tCR9mrKXaeJp5d07E/FUZ8ReIBqZB4f9Rk034yxw9Cpw/XRDWze2MLWzW1sXOM5yPOtbQkxGz5Lim6OJLE+lEKBIXi5V0N9No6GHaWjnYhyaPmzUvBFqITKVAVrIwWsDK4iP5zH6lCeBTdhdmVh+TP4XoxBODmqhCU361E0t4I4nBugxl5UCZpdFvbiNuyELQXFm6XbNLnqyfpng7H86j3Ldx6i+S6GRqIPbvAcOakBOLVx8uidGXazJlcTTnOBJVjdWSxezsH0W61wst0ZfLKm8Y0D+Zyd5nDGcfw2CudRAE6il5zHAbj748ph4eo6ireLqEzv4GXslYSYl/tXZFBpr6rK61gCtck4vqxMqnTtCJzSXThPRsgp3+PUVSjEoiTZb8lZgFcndkamz6Di6AI9u75AG8MpWu7T6P38HP3e52RF/6oRcmsxWRt+VyFotop8Ump1VlVZuqLhx/MoGjthHDG4xHL+WRapcvc4HHc3pNhmhwY7E07+B/4Ys0HcP8r16LTYo1ic8/1pOixF6LgaEn+J6KHEX8YGZ5FCe9CfAAAAAElFTkSuQmCC","aspectRatio":1.7699115044247788,"src":"/static/3b84b25871235ad82038242d53e45213/ee604/551926c16fce61193d7b32284a8bec47.png","srcSet":"/static/3b84b25871235ad82038242d53e45213/69585/551926c16fce61193d7b32284a8bec47.png 200w,\n/static/3b84b25871235ad82038242d53e45213/497c6/551926c16fce61193d7b32284a8bec47.png 400w,\n/static/3b84b25871235ad82038242d53e45213/ee604/551926c16fce61193d7b32284a8bec47.png 800w,\n/static/3b84b25871235ad82038242d53e45213/f3583/551926c16fce61193d7b32284a8bec47.png 1200w","sizes":"(max-width: 800px) 100vw, 800px"}}},"stack":[{"id":95,"title":"VGG16"},{"id":96,"title":"ResNet18"},{"id":97,"title":"Vision Transformer"},{"id":98,"title":"MiniImageNet"},{"id":99,"title":"EuroSAT-RGB"}]},{"github":"https://github.com/moinul7002/Emotion-Detection-from-Bangla-Texts","strapiId":18,"desc":"Since there was no corpus accessible for Bangla texts, we had to build our own corpus first, tokenize the data, extract the features from the texts, analyze the sentiment and classify them into six types of emotions - happy, sad, anger, fear, disgust, and surprise. More than 20K sentences were collected associating specific emotional characteristics labelled with six classes and we also developed four classifier models to detect emotion using different machine learning techniques - SVM, Naive Bayes, Logistic Regression and Decision Tree.","title":"Data Driven Understanding of Emotions from Bangla Texts","url":"https://moinul7002.github.io","category":"Natural Language Processing","image":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACZklEQVQoz0VSO28TQRB2wQ+jhToSbZpUSFQgpCgVJKJAogiICCQiBKGyCxARCnFC4iN2nNgXP85n39O3d3tP4xgFUlHwMbPBUKx2bnZu5ntMqSgKGIaBWq2GMAyh6zoGgwFkFKFnDBAOO9BXF9B7cRexN0KnqeFo7xMSihNHh2wuwzneQBBIZFmKUpqmiOMYUkpE1MR1XRWPhkOEkUTs2xi8W4P1YQOxCJBHAkUS4evhARyjAe/jfYijl8jyCZIkRinLMvi+r1ByI27uOA6s0QgyFDREQmRTpMUUZiBQp/yQ6k9aLZiOjyfDBG+afYz6fcRJcoUwoYBvRsd0Pc+DEwTwJxPYdPe6HWi7u1gql1FaWcH6YQ1CRnhvuiiVLdzcMzGVAnH6lzIjGtFkdZsm0ukU540GLldXcb6zA59YOPReJRSvT07QpcEGxQ5pvnVqoO4GOG0eUw/rqqGmadje3sZ4PIZr2xhTg9n+Pn4vLeEnofLpx06zSUZ4KIhuTEcNPtPx68Z1fH/0UA2VVKcaCiGUjkydtWwQuoQK+r0eBCEZk/MRxbllI+Bct6tO3jrF5b07kBvP4JH+GWvIpvDqmDSRG9frdVQqFWWOSU7bRM8nM/YP9rC4uID1p4/R7nQgyDCmftuc4rkhELo2EtaQjWBUvIN9RkO0OeYVqlar+EwaFnmBM72FtQfL2Hr7ina1jXZdw5eBhWubGm7tdvEtkWrNSgG5+G/3SHhGyYcRWpalcvzGklxc/MBsNkOgakJMiNmh5WMoIkjKcZ2inOe5Wpv5PT/8Pc+xvvM9nb9z7jwnybL///wBxpr7Ue+8ElcAAAAASUVORK5CYII=","aspectRatio":1.7699115044247788,"src":"/static/bf251931620d1ed1e1c1186bfde02907/ee604/062e7d71b09a11bf1579d520879ae346.png","srcSet":"/static/bf251931620d1ed1e1c1186bfde02907/69585/062e7d71b09a11bf1579d520879ae346.png 200w,\n/static/bf251931620d1ed1e1c1186bfde02907/497c6/062e7d71b09a11bf1579d520879ae346.png 400w,\n/static/bf251931620d1ed1e1c1186bfde02907/ee604/062e7d71b09a11bf1579d520879ae346.png 800w,\n/static/bf251931620d1ed1e1c1186bfde02907/f3583/062e7d71b09a11bf1579d520879ae346.png 1200w,\n/static/bf251931620d1ed1e1c1186bfde02907/54967/062e7d71b09a11bf1579d520879ae346.png 1400w","sizes":"(max-width: 800px) 100vw, 800px"}}},"stack":[{"id":86,"title":"Tokenization"},{"id":87,"title":"Stop-word Removal"},{"id":88,"title":"Stemming"},{"id":89,"title":"Classification"}]}]},"allStrapiBlogs":{"nodes":[{"slug":"iccs-2021-1","strapiId":7,"content":"## A Hybrid Secured Approach Combining LSB Steganography and AES using Mosaic Image for Ensuring Data Security\n\n- LSB Matching\n- Steganography\n- Mosaic Images\n- AES\n\n> Presented at ** *[7th International Conference on Cyber Security and Privacy in Communication Networks (ICCS) 2021](https://iccs2021.iaasse.org/call-for-papers.html#guidelines)***. Available Online at ** *[SN Computer Science](https://doi.org/10.1007/s42979-022-01046-8)***\n\nSteganography is a technique of hiding information in digital media such as images, text, audio etc. This digital media is used as the cover to make the private message invisible. Apparently, the attackers donâ€™t have any idea about the original message that is being hidden in the cover media. In this project, the proposed technique has focused on implementing the LSB matching steganography algorithm. For ensuring better security, the AES cryptography technique is used before applying the steganography technique to ensure two-layer security of the private message. Another feature that is used in this project is using mosaic images as the cover media. Mosaic image is capable of hiding up to five LSB layers. Different survey papers show that the success rate of using mosaic images as the cover media is approximately 99% comparing with approximately 50% the success of normal image in case of data hiding. Our proposed approach overcomes the problem of stego image distortion by using mosaic images. The improved LSB steganography algorithm also effectively handles mosaic images. Using a better version of LSB, Stego images were given more excellent PSNR value than other approaches when the hidden message was integrated into the mosaic image. Compared with different space domain strategies, the PSNR value of our proposed system is 85.65 dB for a maximum text capacity of 32 bytes.","desc":"A Hybrid Secured Approach Combining LSB Steganography and AES using Mosaic Image for Ensuring Data Security","date":"February 3rd, 2022","id":"Blogs_7","title":"ICCS 2021","category":"Springer","image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAIF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQD/2gAMAwEAAhADEAAAAduRLBf/xAAYEAACAwAAAAAAAAAAAAAAAAAAARARIv/aAAgBAQABBQJ2aj//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAWEAADAAAAAAAAAAAAAAAAAAAAEEH/2gAIAQEABj8CIv/EABkQAAEFAAAAAAAAAAAAAAAAABEAEDFRkf/aAAgBAQABPyGAI003/9oADAMBAAIAAwAAABAEP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABkQAQEAAwEAAAAAAAAAAAAAACERAAEQYf/aAAgBAQABPxBBlbmhvujn/9k=","aspectRatio":2.4096385542168677,"src":"/static/eb3cbb774b0d6fe24cd324b98a3ff96e/ee1c2/ada027d85355a4ff8fa70ec460035e3a.jpg","srcSet":"/static/eb3cbb774b0d6fe24cd324b98a3ff96e/f836f/ada027d85355a4ff8fa70ec460035e3a.jpg 200w,\n/static/eb3cbb774b0d6fe24cd324b98a3ff96e/ee1c2/ada027d85355a4ff8fa70ec460035e3a.jpg 348w","sizes":"(max-width: 348px) 100vw, 348px"}}}},{"slug":"security-and-privacy","strapiId":6,"content":"## Effectively Predicting Cyber-Attacks through Isolation Forest Learning-based Outlier Detection\n\n- Cyber Anomaly\n- Isolation Forest\n- k-Means\n- DBScan\n\n> Available Online at ** *[Security and Privacy Journal - Wiley](https://doi.org/10.1002/spy2.212)***\n\nDue to the popularity of Internet of Things devices, the exponential progress of computer networks, and a plethora of associated applications, cybersecurity has recently attracted much attention in light of today's security problems. As a result, detecting various cyber-attacks within a network and developing an effective cyber-attacks prediction model that plays a crucial part in today's defense has become increasingly critical. Modeling cyber-attacks effectively, on the other hand, is challenging because modern security datasets hold a large number of dimensions of security features and may contain outliers. To accomplish this, we provide an approach for categorizing cyber-attacks effectively through isolation forest learning-based outlier detection. Additionally, we apply a variety of popular machine learning approaches to assess the performance of cyber-attacks prediction models, including logistic regression, support vector machine, AdaBoost classifier, naive Bayes, and K-nearest neighbor. We evaluated the efficacy of our approach by running tests on three network intrusion datasets (KDD Cup 99, CIC-IDS2017, and UNSW-NB15) and computing the precision, recall, and accuracy. Experiments demonstrate that eliminating outliers improves the prediction accuracy of cyber-attacks for different classifiers. Additionally, we compare the isolation forest learning-based outlier detection model to other well-known outlier detection techniques, DBSCAN and k-means, and measure the effectiveness of our model.","desc":"Effectively Predicting Cyber-Attacks through Isolation Forest Learning-based Outlier Detection","date":"February 9th, 2022","id":"Blogs_6","title":"Security and Privacy","category":"Wiley","image":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAqUlEQVQoz7XSMQuCUBSGYa/WEOhgQUI4FFIQUUMUVIMgQXMQ9APa2oOGcImWhrZ+cK/wQSG3TS88nKMcPq9eHee7jFSyKgv6DVthgTZCDBGjgQCe5jqaKfi659sCp8hxwh0j9WucFdTEA6keeMUOSflNXdUnDnhhjCMyXHTdxRtbze9xU+/ZdtlHS7UYmGGAjYIn2tESPUSY/zsHU8ehGks1+iRuqbf+ah9m7wyGhzpD0gAAAABJRU5ErkJggg==","aspectRatio":2.5,"src":"/static/f4fbf19154a2d265cfec16b456f0f868/ee604/befd7d82f730f3e5539fc8d79beeface.png","srcSet":"/static/f4fbf19154a2d265cfec16b456f0f868/69585/befd7d82f730f3e5539fc8d79beeface.png 200w,\n/static/f4fbf19154a2d265cfec16b456f0f868/497c6/befd7d82f730f3e5539fc8d79beeface.png 400w,\n/static/f4fbf19154a2d265cfec16b456f0f868/ee604/befd7d82f730f3e5539fc8d79beeface.png 800w,\n/static/f4fbf19154a2d265cfec16b456f0f868/f3583/befd7d82f730f3e5539fc8d79beeface.png 1200w,\n/static/f4fbf19154a2d265cfec16b456f0f868/5707d/befd7d82f730f3e5539fc8d79beeface.png 1600w,\n/static/f4fbf19154a2d265cfec16b456f0f868/ed396/befd7d82f730f3e5539fc8d79beeface.png 2000w","sizes":"(max-width: 800px) 100vw, 800px"}}}},{"slug":"iccit-2021","strapiId":5,"content":"## IRFD: A Feature Engineering based Ensemble Classification for Detecting Electricity Fraud in Traditional Meters\n\n- Anomaly Detection\n- Isolation Forest\n- RFECV\n- Stratified K-Fold Cross-Validation\n- Random Forest\n\n> Presented at the ** *[24th International Conference on Computer and Information Technology (ICCIT 2021)](https://iccit.org.bd/2021/)***. Available Online at ** *[IEEE Xplore](https://doi.org/10.1109/iccit54785.2021.9689842)***\n\nNations have suffered significant economic losses as a result of non-technical electric losses resulting from power fraud. It is a criminal act of stealing electricity by applying various mechanisms that incorporate unauthorized tapping to the power line, bypassing the smart meter, etc. Electricity theft is a significant concern for not only developing countries but also developed countries as well. However, for most developing countries, the implications are catastrophic, given that their usage is always less than their demands. Electricity theft must be detected precisely and quickly in order to be mitigated. In our study, we have proposed a method of predictive ensemble machine learning techniques (IRFD) with a novel combination of feature distinction methods to detect electricity theft. In our proposed model, we have combined feature selection technique, Recursive Feature Elimination with Stratified 10-Fold cross-validation (RFECV) and Isolation Forest (IF), to identify and remove outliers along with several machine learning classifiers to forecast the theft of electricity. This study additionally enhances the management of highly imbalanced fraudulent data with Borderline-SMOTE with SVM (SVMSMOTE) and feature scaling with StandardScaler. Following the study, the Random Forest classifier observed a higher degree of accuracy (97.06%) with higher precision, recall, and F1-Score. To evaluate the efficacy of our proposed model, comparative analysis of the classification metrics is also assessed with several machine learning classifiers like Logistic Regression, Gradient Boosting, XGBoost, AdaBoost, KNN, ANN, along with Random Forest before and after fitting our proposed feature engineering techniques.\n\n","desc":"IRFD: A Feature Engineering based Ensemble Classification for Detecting Electricity Fraud in Traditional Meters","date":"January 28th, 2022","id":"Blogs_5","title":"ICCIT 2021","category":"IEEE","image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAIDAQX/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAAB7GvNKDB//8QAGBAAAwEBAAAAAAAAAAAAAAAAAAEhEjH/2gAIAQEAAQUCm4JR15Fz/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGhAAAgIDAAAAAAAAAAAAAAAAAAEQIRExQf/aAAgBAQAGPwLFj3R2HH//xAAbEAEAAgMBAQAAAAAAAAAAAAABABExQVFh0f/aAAgBAQABPyFyPd6mKtQTYy7Cga7cvX1Eospn/9oADAMBAAIAAwAAABDX3//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABwQAQADAAIDAAAAAAAAAAAAAAEAESFBcTFRgf/aAAgBAQABPxAikbPLiLUc4Dr1ALA1WElaUGgx9OYirbthy69RguDS7qf/2Q==","aspectRatio":1.3245033112582782,"src":"/static/367abe1527c4b5e2af88ae9b24f667d0/14b42/8a4d6dc7515696444bffdb538407116f.jpg","srcSet":"/static/367abe1527c4b5e2af88ae9b24f667d0/f836f/8a4d6dc7515696444bffdb538407116f.jpg 200w,\n/static/367abe1527c4b5e2af88ae9b24f667d0/2244e/8a4d6dc7515696444bffdb538407116f.jpg 400w,\n/static/367abe1527c4b5e2af88ae9b24f667d0/14b42/8a4d6dc7515696444bffdb538407116f.jpg 800w,\n/static/367abe1527c4b5e2af88ae9b24f667d0/47498/8a4d6dc7515696444bffdb538407116f.jpg 1200w,\n/static/367abe1527c4b5e2af88ae9b24f667d0/5a5ee/8a4d6dc7515696444bffdb538407116f.jpg 1336w","sizes":"(max-width: 800px) 100vw, 800px"}}}}]}},"pageContext":{}},"staticQueryHashes":["1469344777","1991767544","454067985"]}